This repo contains code for a data, parameter and memory efficient deep learning classifier for 3D images.

Classifying 3D images is a very important task in medical research. Machine learning models that can classify MRIs or CT scan images into healthy and diseased or identify the subtype of disease can be used as an aid in clinical diagnosis sometimes resulting in significantly earlier diagnoses. The radiomics hypothesis suggests that there is more information in medical images than we currently believe. Deep learning models could possibly be one of the ways to unlock this potential. However, there are several challenges in training and deploying deep learning models in medical imaging. The biggest hurdle is the lack of large datasets compared to other sectors such as IT. Here we address this issue by creating a data efficient or generalisable model with a relatively low number of trainable parameters. Another challenge specific to 3D medical imaging is the large size of images and therefore large GPU memory requirement for training models on them. Our model solves this issue by essentially doing things upside down compared to other research in this area.

Here are our original contributions:

Several similar studies have used transformer layers in their classifier. Transformers have become popular as they are extremely scalable models. They are not of particular interest to us because we are trying to create a parameter efficient model. In addition there are several studies which hint at the possibility that recurrent neural networks have inductive biases that transformers do not have. (https://openreview.net/pdf?id=YmA86Zo-P_t) This may boost their generalisability. Recent studies have solved the issues that made recurrent neural networks unfavorable such as lack of parallelisation and vanishing or exploding gradients using linear recurrent units. (https://arxiv.org/pdf/2303.06349) Here we create a linear recurrent unit that takes in 2D images as input at every time step.

Other models developed recently first use 3D and slice-wise 2D convolutions before using a transformer or fully connected layer. (https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_M3T_Three-Dimensional_Medical_Image_Classifier_Using_Multi-Plane_and_Multi-Slice_Transformer_CVPR_2022_paper.pdf) Pretrained 3D CNNs and  pretrained 2D CNNs simultaneously applied on every slice can cause very high GPU memory requirements. Here we use the linear recurrent units to get a significantly reduced number of slices that can be thought of as weighted averages of all the slices and then apply pretrained 2D CNNs on them.
